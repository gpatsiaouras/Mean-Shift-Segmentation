import time
import cv2
import numpy as np
import scipy.io
from skimage import io, color
import matplotlib.pyplot as plt
import progressbar
from threading import Thread
from mpl_toolkits.mplot3d import Axes3D


def plot_data_points_and_peaks(data, model):
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')
    ax.scatter(data[0, np.where(model.labels == 0)], data[1, np.where(model.labels == 0)],
               data[2, np.where(model.labels == 0)], c="lightblue")
    ax.scatter(data[0, np.where(model.labels == 1)], data[1, np.where(model.labels == 1)],
               data[2, np.where(model.labels == 1)], c="lightgreen")
    peaks = np.array(model.peaks).reshape(len(model.peaks), 3).T
    ax.scatter(peaks[0], peaks[1], peaks[2], c="red")
    plt.show()


def get_3d_representation(image):
    """
    Convert the image to lab colors. Create an image_array numpy array with size 3.
    :param image: Image read from cv2
    :return: Array representation of image
    """
    image = color.rgb2lab(image)
    image_array = np.zeros((3, image.shape[0] * image.shape[1]))
    l, a, b = cv2.split(image)
    image_array[0, :] = l.flatten()
    image_array[1, :] = a.flatten()
    image_array[2, :] = b.flatten()

    return image_array


def get_5d_representation(image):
    """
    Convert the image to lab colors. Create an image_array numpy array with size 5, width, height.
    :param image: Image read from cv2
    :return: Array representation of image
    """
    image = color.rgb2lab(image)
    image_array = np.zeros((5, image.shape[0] * image.shape[1]))
    l, a, b = cv2.split(image)
    image_array[0, :] = l.flatten()
    image_array[1, :] = a.flatten()
    image_array[2, :] = b.flatten()
    image_array[3, :] = np.tile(np.array(range(0, image.shape[0])), image.shape[1]).flatten()
    image_array[4, :] = np.tile(np.array(range(0, image.shape[1])), image.shape[0]).flatten()

    return image_array


class MeanShiftSegmentation:
    def __init__(self, data, radius, c):
        """
        Assigns data and radius
        Initiates a threshold and a conversion threshold, an empty list to save peaks,
        an vector of labels with default value -1
        :param data:
        :param radius:
        """
        self.data = data
        self.radius = radius
        self.c = c
        self.conversion_threshold = self.radius / 2
        self.threshold = 0.01  # 0.01
        self.peaks = []
        # Initiate labels with -1 values indicating that there is no label assigned yet
        self.labels = np.ones(data.shape[1]) * -1

    def find_peak(self, previous_data_point):
        """
        Applies iterative process that based on a sphere of data generated by a radius
        it finds the mean point and then shifts the sphere to the new mean point until the
        sphere stops moving.
        :param previous_data_point:
        :return mean_data_point: Peak found
        """
        points_keys, distances = self.get_data_in_radius_from_point(previous_data_point)
        mean_data_point = np.mean(self.data[:, points_keys], axis=1)
        while not self.converged(mean_data_point, previous_data_point):
            previous_data_point = mean_data_point
            points_keys, distances = self.get_data_in_radius_from_point(mean_data_point)
            mean_data_point = np.mean(self.data[:, points_keys], axis=1)

        return mean_data_point

    def find_peak_opt(self, previous_data_point):
        """
        Finds peak point as find_peak but also returns the points that should be associated with the label
        defined by this peak according to the speedups.
        :param previous_data_point:
        :return mean_data_point, points_in_radius: Peak found and points at range
        """
        # Creating an array of the same feature size as data with False default value indicating that
        # no feature should be associated with label.
        points_to_be_associated = np.full((self.data.shape[1],), False, dtype=bool)

        points_keys, distances = self.get_data_in_radius_from_point(previous_data_point)
        mean_data_point = np.mean(self.data[:, points_keys], axis=1)

        while not self.converged(mean_data_point, previous_data_point):
            previous_data_point = mean_data_point

            # Get the new points inside the sphere
            points_keys, distances = self.get_data_in_radius_from_point(mean_data_point)

            # Second optimization. Take the points in range radius/c
            points_keys_2 = np.argwhere(distances < self.radius / self.c)

            # Second optimization Save the path of the algorithm
            points_to_be_associated[points_keys_2] = True

            # Recalculate mean point
            mean_data_point = np.mean(self.data[:, points_keys], axis=1)

        # In the existing point keys also add the data in radius distance from the last mean point.
        # as instructed by the first optimization
        points_to_be_associated[points_keys] = True
        return mean_data_point, points_keys

    def mean_shift(self):
        """
        Mean shift implementation, iterates over data points and for each one it finds
        the peak and assigns the approriate label.
        """
        start_time = time.time()
        print("Running mean shift algorithm")
        for i in progressbar.progressbar(range(self.data.shape[1]), redirect_stdout=True):
            peak = self.find_peak(self.data[:, i].reshape(self.data.shape[0], 1))
            self.labels[i] = self.get_label_for_point(peak)

        print("\rPeaks found: {0}, Exec Time Mean Shift: {1:.2f} seconds"
              .format(len(self.peaks), time.time() - start_time))

    def mean_shift_opt(self):
        """
        Optimized mean shift algorithm applying optimization of basin of attraction and
        points along the search path association with the converged peak.
        """
        start_time = time.time()
        print("Running mean shift algorithm optimized")
        find_peaks_called = 0
        for i in progressbar.progressbar(range(self.data.shape[1]), redirect_stdout=True):
            if self.labels[i] == -1:
                peak, points_in_radius = self.find_peak_opt(self.data[:, i].reshape(self.data.shape[0], 1))
                self.labels[i] = self.get_label_for_point(peak)
                self.labels[points_in_radius] = self.labels[i]
                find_peaks_called += 1

        print("\rPeaks found: {0}, Exec Time Optimized Mean Shift: {1:.2f} seconds, Called find peaks: {2:.2f}%"
              .format(len(self.peaks), time.time() - start_time, find_peaks_called / self.data.shape[1] * 100))

    def get_data_in_radius_from_point(self, cluster_point):
        """
        Retrieves distances of all data points from specific point, then returns the indices
        of the points that have a distance less than the radius, but also the distances from the points.
        The latter one is later used in findPeak for optimization reasons
        :param cluster_point: Center of sphere
        :return points_in_range, distances:
        """
        distances_from_point = np.linalg.norm(cluster_point - self.data, axis=0)
        return np.argwhere(distances_from_point < self.radius), distances_from_point

    def converged(self, mean_data_point, previous_data_point):
        """
        Checks if the mean data point is close enough to the previous mean data point
        and returns true if it is less than the threshold.
        :param mean_data_point: Current center of sphere
        :param previous_data_point: Previous center of sphere
        :return True or False: True if it converged, False if not
        """
        return np.linalg.norm(mean_data_point - previous_data_point) < self.threshold

    def get_label_for_point(self, new_peak):
        """
        Searches if the new_peak found already exists in the peaks list by
        using a threshold between the values. If the peak exists it returns the index
        of the peak, otherwise adds the peak to the list and returns last index.
        :param new_peak: New peak found for this point
        :return index of peak: Index of the peak in the peaks list
        """
        # peaks_array = np.array(self.peaks)
        for peak_idx in range(len(self.peaks)):
            if (np.abs(new_peak - self.peaks[peak_idx]) < self.conversion_threshold).all():
                return peak_idx

        self.peaks.append(new_peak)

        return len(self.peaks) - 1


def run_mean_shift_on_test_dataset():
    """
    Debugs the algorithm by using the test dataset provided in the
    description of the assignment, and prints the data representation
    and the peaks found. Runs both with no optimization and with optimization
    to print time difference.
    """
    radius = 2
    c = 4

    # Read debug data
    data = np.array(scipy.io.loadmat('../resources/pts.mat')['data'])

    # Run Without Optimization
    image_seg = MeanShiftSegmentation(data, radius, c)
    image_seg.mean_shift()

    # Run With Optimization
    image_seg_opt = MeanShiftSegmentation(data, radius, c)
    image_seg_opt.mean_shift_opt()

    # Plot data points
    plot_data_points_and_peaks(data, image_seg_opt)


def run_mean_shift_on_image(filename, radius, c, five_dimensions=False, show_images=False):
    """
    Runs the mean shift algorithm on images. The filename defines the image
    that we want to segment, located inside the resources folder. It runs
    using the optimized version of mean shift and then creates an empty image
    and by using the labels array from the segmentation algorithm it prints
    the segments of the image on the overlay.
    """
    # Read image
    image = cv2.imread("../resources/" + filename)

    if five_dimensions:
        image_array = get_5d_representation(image)
    else:
        image_array = get_3d_representation(image)

    # Run With Optimization on the image_array
    image_seg_opt = MeanShiftSegmentation(image_array, radius, c)
    image_seg_opt.mean_shift_opt()

    # Create an empty overlay array to be used for the segmented image
    overlay = np.zeros((3, image_seg_opt.labels.shape[0]))

    # For each of the segments replace all features having this label
    # with the l,a,b values of the peak for this label.
    for segment in np.unique(image_seg_opt.labels):
        overlay[:, image_seg_opt.labels == segment] = image_seg_opt.peaks[int(segment)][:3]

    # Merge the layers back, Unflatten the array and convert back to rgb
    overlay = cv2.merge((overlay[0, :], overlay[1, :], overlay[2, :]))
    overlay = overlay.reshape(image.shape[0], image.shape[1], 3)
    overlay = color.lab2rgb(overlay)

    # Save the image to skip resegmenting and show it if user asked for it.
    cv2.imwrite("../out/{0}_rad_{1}_c_{2}{3}.jpg"
                .format(filename.split(".")[0], radius, c, ("_5d" if five_dimensions else "")), overlay * 255)
    if show_images:
        cv2.imshow('Original Image', image)
        cv2.imshow('Segmented Image', overlay)
        cv2.waitKey(0)
        cv2.destroyAllWindows()


if __name__ == "__main__":
    # Uncomment to run on the test data
    run_mean_shift_on_test_dataset()

    # Run in multithread mode if your computer has 4 threads and more
    # t1 = Thread(target=run_mean_shift_on_image, args=("181091_xs.jpg", 4, 2, True, False,))
    # t1.start()
    # t2 = Thread(target=run_mean_shift_on_image, args=("181091_xs.jpg", 8, 2, True, False,))
    # t2.start()
    # t3 = Thread(target=run_mean_shift_on_image, args=("181091_xs.jpg", 12, 5, False, False,))
    # t3.start()
    # t4 = Thread(target=run_mean_shift_on_image, args=("181091_xs.jpg", 16, 5, False, False,))
    # t4.start()

    # Or run on single mode
    run_mean_shift_on_image("181091_xs.jpg", radius=24, c=2, five_dimensions=False, show_images=False)
